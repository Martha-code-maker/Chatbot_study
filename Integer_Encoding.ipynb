{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Integer_Encoding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+Ho1pZ+Rz5S/o3ctwL/ZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Martha-code-maker/Chatbot_study/blob/main/Integer_Encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qRkas_mibE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4d38d9-9da8-477f-ba01-d626e89a78bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
      ],
      "metadata": {
        "id": "IPOmSRswkmVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. dictionary 사용"
      ],
      "metadata": {
        "id": "vjd5L9lq33_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "문장 토큰화"
      ],
      "metadata": {
        "id": "hdw6yteDlDxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnESd7ewkqH_",
        "outputId": "f280e28c-e9e6-4946-d007-d4d24e23dd86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어토큰화"
      ],
      "metadata": {
        "id": "WQG50F4jlNh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voca = {}\n",
        "preprocess__sentece = []\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "for sentence in sentences:\n",
        "  tokenized_sentence = word_tokenize(sentence)\n",
        "  result = []\n",
        "\n",
        "  for word in tokenized_sentence:\n",
        "    word = word.lower()\n",
        "    if word not in stop_words:\n",
        "      if len(word) > 2:\n",
        "        # 불용어가 아니면서 단어의 길이가 2이상인 단어만 추가\n",
        "        result.append(word)\n",
        "        if word not in voca:  #voca안에는 단어의 빈도수 정보가 포함됨\n",
        "          voca[word] = 0\n",
        "        voca[word] += 1\n",
        "  preprocess__sentece.append(result)\n",
        "print(preprocess__sentece)\n",
        "print('단어 빈도 수:', voca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6INyVIdk289",
        "outputId": "f2a291c1-f660-4fe4-c6c8-95f0c4e98943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
            "단어 빈도 수: {'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "빈도수 높은 단어 순으로 정렬"
      ],
      "metadata": {
        "id": "q_qzjH0bnBoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voca_sorted = sorted(voca.items(), key = lambda x: x[1], reverse = True)\n",
        "print(voca_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFw469Zcm1Iv",
        "outputId": "29767184-c97a-40d8-d2d9-6da6ad459040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n",
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정렬된 단어 별로 인덱스 부여하기"
      ],
      "metadata": {
        "id": "FzLpTRx3s7uY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in voca_sorted:\n",
        "  if frequency > 1:   #빈도수가 1인 단어 제외\n",
        "    i = i+1\n",
        "    word_to_index[word] = i\n",
        "\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r24YOJ-GtAHI",
        "outputId": "7c1ae9b0-3c46-4822-dbbf-e6b5c9b0ac43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "상위 n개 단어만 사용할 때"
      ],
      "metadata": {
        "id": "X1lL09o-zvn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "word_frequency = [word for word , index in word_to_index.items() if index >= vocab_size + 1]\n",
        "\n",
        "#5초과인 인덱스 단어 정보 삭제\n",
        "for w in word_frequency:\n",
        "  del word_to_index[w]\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtEhLFbKzzYF",
        "outputId": "57d1ddb1-8744-45b8-e400-8ac14e437cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of Vocabulary(OOV) : 단어 집합에 없는 단어"
      ],
      "metadata": {
        "id": "ddMSouO62Yo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index[\"OOV\"] = len(word_to_index) + 1"
      ],
      "metadata": {
        "id": "Gicb3pAD2XbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "encoding sentence"
      ],
      "metadata": {
        "id": "12cMqVX-2njE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sentences = []\n",
        "for sentence in preprocess__sentece:\n",
        "  encoded_sentence = []\n",
        "  for word in sentence :\n",
        "    try:\n",
        "      encoded_sentence.append(word_to_index[word])\n",
        "    except KeyError:\n",
        "      encoded_sentence.append(word_to_index['OOV'])\n",
        "  encoded_sentences.append(encoded_sentence)\n",
        "print(encoded_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hULFh9f2pQ6",
        "outputId": "9aaf2b65-51f4-4ef2-e492-e0f5ebd9c7cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Counter 사용"
      ],
      "metadata": {
        "id": "Aa8dcjz-4zsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "-cYSDvC841yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "token화 된 문장들의 경계를 제거하고 하나의 리스트로 만들기"
      ],
      "metadata": {
        "id": "EZkV0tRl5Bi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_words_list = sum(preprocess__sentece,[])"
      ],
      "metadata": {
        "id": "_DaZ_3Ln5Ceg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Counter(all_words_list)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwjNCu8W4_Va",
        "outputId": "00575191-77b5-4e35-e65e-8507ef02cb0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "빈도수 상위 5개 단어만 저장하기 (most_common)"
      ],
      "metadata": {
        "id": "OASfo3rv5xRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vocab = vocab.most_common(5)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8X7T3ET5g2c",
        "outputId": "9814c835-e66a-4ef3-ee15-96e31f149be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "높은 빈도수 단어에 낮은 정수 인덱스 부여하기"
      ],
      "metadata": {
        "id": "yRDkh6qK6UwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab:\n",
        "  i = i + 1\n",
        "  word_to_index[word] = i\n",
        "\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx7_0yYD6aWR",
        "outputId": "d48449f8-b6b9-43b0-b85b-16e1984e7a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. enumerate 이해하기"
      ],
      "metadata": {
        "id": "82bbwa627QsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = ['a','b','c','d']\n",
        "for index, word in enumerate(word):\n",
        "  print(index, word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QihD0Tfx7TWn",
        "outputId": "88fdeb6b-6007-417e-9e8e-6b0fff9c0e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 a\n",
            "1 b\n",
            "2 c\n",
            "3 d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Keras 텍스트 전처리"
      ],
      "metadata": {
        "id": "tgM6VLwl8lWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "qCCzP9FK8kwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocess__sentece) #빈도수 기준으로 단어 집합 생성\n",
        "print(tokenizer.word_index)\n",
        "print(tokenizer.word_counts)\n",
        "print(tokenizer.texts_to_sequences(preprocess__sentece))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zowSJZ4L8t9X",
        "outputId": "b9291d8e-4d55-4595-da50-875b3cd88ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n",
            "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n",
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "상위 5개만 사용"
      ],
      "metadata": {
        "id": "pmgscrpp9yes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "word_frequency =[word for word, index in tokenizer.word_index.items() if index >= vocab_size+1]\n",
        "for word in word_frequency:\n",
        "  del tokenizer.word_index[word]\n",
        "  del tokenizer.word_counts[word]\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(tokenizer.word_counts)\n",
        "print(tokenizer.texts_to_sequences(preprocess__sentece))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGT6NMow9SGm",
        "outputId": "f210952c-1441-4e42-c0c9-f5739092dd8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n",
            "OrderedDict([('barber', 8), ('person', 3), ('huge', 5), ('secret', 6), ('kept', 4)])\n",
            "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
          ]
        }
      ]
    }
  ]
}